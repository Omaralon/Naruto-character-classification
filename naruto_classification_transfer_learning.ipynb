{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naruto_classification_transfer_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omaralon/Naruto-character-classification/blob/master/naruto_classification_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFAdFeASFk06",
        "colab_type": "text"
      },
      "source": [
        "# Clasificación de personajes de Naruto utilizando Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfUO35hJmIqJ",
        "colab_type": "text"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "- Aprender y utilizar una técnica muy popular en Deep Learning para aquellas ocasiones en las que no tenemos suficiente información y queremos una respuesta rápida y eficaz en cuanto a tiempo de entrenamiento.\n",
        "- Familiarizarse con herramientas utilizadas en el ámbito de Machine Learning como lo es Tensorflow.\n",
        "- Probar el funcionamiento del aprendizaje por transferencia al utilizar un dataset de imágenes recopilado por nosotros.\n",
        "- Conocer un poco del flujo y las técnicas para la clasificación de imágenes por medio de redes neuronales convolucionales.\n",
        "- Informarse acerca de los diferentes modelos oficiales preentrenados por Google para aplicarlos en un ambiente móvil, en dónde el espacio y el poder computacional es más limitado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GcOqV8EPMh",
        "colab_type": "text"
      },
      "source": [
        "## Introducción teórica \n",
        "<image src=https://cdn-images-1.medium.com/max/1600/1*9GTEzcO8KxxrfutmtsPs3Q.png width=700>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAZ0F99PDf9i",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué es el Deep Learning?\n",
        "\n",
        "<image src=https://www.smartpanel.com/wp-content/uploads/2018/04/evolucion-machine-learning-e1523271968363-1024x558.png width=700>\n",
        "\n",
        "Deep Learning o aprendizaje profundo se define como un algoritmo automático estructurado o jerárquico que emula el aprendizaje humano con el fin de obtener ciertos conocimientos. Destaca porque no requiere de reglas programadas previamente, sino que el propio sistema es capaz de «aprender» por sí mismo para efectuar una tarea a través de una fase previa de entrenamiento. \n",
        "\n",
        "A su vez, también se caracteriza por estar compuesto por redes neuronales artificiales entrelazadas para el procesamiento de información. Se emplea principalmente para la automatización de análisis predictivos.\n",
        "\n",
        "\n",
        "![](https://www.smartpanel.com/wp-content/uploads/2018/04/red-neuronas-artificiales.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uud_MxVDEeD9",
        "colab_type": "text"
      },
      "source": [
        "Los algoritmos que componen un sistema de aprendizaje profundo se encuentra en diferentes capas neuronales compuestas por pesos (números). El sistema está dividido principalmente en 3 capas:\n",
        "\n",
        "**1. Capa de entrada (Input Layer):** Está compuesto por las neuronas que asimilan los datos de entrada, como por ejemplo imagen o una tabla de datos.\n",
        "\n",
        "\n",
        "**2. Capa oculta (Hidden Layer):** Es la red que realiza el procesamiento de información y hacen los cálculos intermedios. Cada más neuronas en esta capa haya, más complejos son los cálculos que se efectúan.\n",
        "\n",
        "\n",
        "**3. Salida (Output Layer):** Es el último eslabón de la cadena, y es la red que toma la decisión o realizar alguna conclusión aportando datos de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEivE83mEziD",
        "colab_type": "text"
      },
      "source": [
        "#### Ejemplo de Deep Learning\n",
        "Suponiendo que queremos que una máquina sea capaz de identificar si hay algún perro dentro de una imagen. Para ello tendríamos que programar un algoritmo de una manera semejante a la explicación anterior, dividiendo las funciones de cada capa neuronal en un proceso de entrada, procesamiento y salida.\n",
        "\n",
        "<img src=https://www.smartpanel.com/wp-content/uploads/2018/04/deep-learning-proceso.png width=700>\n",
        "\n",
        "Para la **entrada de datos**, tendríamos que crear una capa que asimile la información introducida. En este caso, necesitaríamos que las neuronas desmembraran la imagen en píxeles, así, cada trozo de imagen se envía a las diferentes neuronas de la segunda capa.\n",
        "\n",
        "Después, la **capa de segundo nivel** tiene como objetivo procesar cada uno de los pixeles delimitando los bordes dentro de los pixeles (separando los vectores dentro de los pixeles).\n",
        "\n",
        "En el **tercer nivel** se combinarán los bordes para diseñar las formas, y constituir cada uno de los objetos de la imagen.\n",
        "\n",
        "En la capa de **cuarto nivel**, se utilizan los filtros del sistema para reconocer qué objetos son perros, y cuáles no, cómo pueden ser tener cuatro patas, tener una cola y un hocico. Como último paso, la capa 4 traspasa los datos a la última capa, el cual combina las características identificadas para reconocerse si es un «perro» o no por medio de conclusiones parciales, es decir, este fragmento es una cola de un animal, por tanto sí puede ser un perro. Si tiene cuatro patas, sí tiene características de perro… así hasta entregar todos los fragmentos de información a la capa de salida y que este ofrezca una conclusión.\n",
        "\n",
        "A grandes rasgos, puede decirse que el Deep Learning funciona reduciendo errores, y tratando de aumentar el intervalo de confianza. Si tuviéramos que basarnos solo en la segunda capa, se puede decir que el intervalo de confianza de que haya un perro es de 70%, luego, si lo procesa la tercera capa aumentaría hasta el 77%… Así hasta reducir el margen de error casi a 0.\n",
        "\n",
        "Para que la máquina aprenda, tiene que pasar por un proceso didáctico el cual combina un aprendizaje supervisado (un humano etiqueta en la imagen que es un perro), y un aprendizaje no supervisado (la máquina encuentra sus propios patrones para establecer relaciones a partir de los datos aportados).\n",
        "\n",
        "Cada más cerca esté la neurona de la capa de salida, más entrenamiento supervisado requerirá para perfeccionarse. Esto ocurre debido a que las primeras capas tratan de procesar los datos de modo que se puedan reconocer objetos complejos, en cambio, las capas más profundas requieren de mayor atención humana, ya que los cálculos son cada vez más complejos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl6RXYOFGLHV",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué es una red neuronal convolucional (CNN)?\n",
        "Una red neuronal convolucional es un tipo de red multicapa que consta de diversas capas convolucionales y de pooling (submuestreo) alternadas, y al final tiene una serie de capas full-connected como una red perceptrón multicapa. La entrada de una red capa convolucional suele ser, generalmente, una imagen m x m x r, donde m es tanto la altura como el ancho de la imagen y r es el número de canales. Las capas convolucionales tienen k filtros (o kernels) cuyas dimensiones son n x n x q , donde  n y q son elegidas por el diseñador (generalmente q suele ser igual a r).\n",
        "\n",
        "Cada filtro genera mediante convolución un mapa de rasgos o características de tamaño (m−n+1)  x (m-n+1) x p, siendo p el número de filtros que se desean usar. \n",
        "Después cada mapa es sub-muestreado en la capa de pooling con la operación “mean pooling” o “max pooling” sobre regiones contiguas de tamaño p x p donde p puede tomar valores desde 2 para imágenes pequeñas hasta, comúnmente, no más de 5 para imágenes grandes. Antes o después del submuestreo, se aplica una función de activación sigmoidal más un sesgo para cada mapa de rasgos. \n",
        "\n",
        "\n",
        "<image src=https://iaarhub.github.io/images/cnn.png width=800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG6nAtAGHL-C",
        "colab_type": "text"
      },
      "source": [
        "### Estructura de las Redes Neuronales Convolucionales\n",
        "\n",
        "En general, las redes neuronales convolucionales van a estar construidas con una estructura que contendrá 3 tipos distintos de capas:\n",
        "\n",
        "1. Una capa convolucional, que es la que le da el nombre a la red.\n",
        "\n",
        "\n",
        "2. Una capa de reducción o de pooling, la cual va a reducir la cantidad de parámetros al quedarse con las características más comunes.\n",
        "\n",
        "\n",
        "3. Una capa clasificadora totalmente conectada, la cual nos va dar el resultado final de la red.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z030GoZ_Hef3",
        "colab_type": "text"
      },
      "source": [
        "#### Capa Convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN3AoCe_Hg2V",
        "colab_type": "text"
      },
      "source": [
        "La operación de convolución recibe como entrada o input la imagen y luego aplica sobre ella un filtro o kernel que nos devuelve un mapa de las características de la imagen original, de esta forma logramos reducir el tamaño de los parámetros. La convolución aprovecha tres ideas importantes que pueden ayudar a mejorar cualquier sistema de machine learning, ellas son:\n",
        "\n",
        "1. Interacciones dispersas, ya que al aplicar un filtro de menor tamaño sobre la entrada original podemos reducir drásticamente la cantidad de parámetros y cálculos.\n",
        "\n",
        "2. Los parámetros compartidos, que hace referencia a compartir los parámetros entre los distintos tipos de filtros, ayudando también a mejorar la eficiencia del sistema\n",
        "\n",
        "3. Las representaciones equivariante, que indican que si las entradas cambian, las salidas van a cambiar también en forma similar.\n",
        "\n",
        "![](https://relopezbriega.github.io/images/conv_layer.png)\n",
        "\n",
        "Por otra parte, la convolución proporciona un medio para trabajar con entradas de tamaño variable, lo que puede ser también muy conveniente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IVWN3bSIQDd",
        "colab_type": "text"
      },
      "source": [
        "#### Capa de reducción o pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Vd2sj9IURK",
        "colab_type": "text"
      },
      "source": [
        "La capa de reducción o pooling se coloca generalmente después de la capa convolucional. Su utilidad principal radica en la reducción de las dimensiones espaciales (ancho x alto) del volumen de entrada para la siguiente capa convolucional. No afecta a la dimensión de profundidad del volumen. La operación realizada por esta capa también se llama reducción de muestreo, ya que la reducción de tamaño conduce también a la pérdida de información. Sin embargo, una pérdida de este tipo puede ser beneficioso para la red por dos razones:\n",
        "\n",
        "1. Disminución en el tamaño conduce a una menor sobrecarga de cálculo para las próximas capas de la red.\n",
        "\n",
        "2. Reducir el sobreajuste.\n",
        "\n",
        "![](https://relopezbriega.github.io/images/Max_pooling.png)\n",
        "\n",
        "La operación que se suele utilizar en esta capa es max-pooling, que divide a la imagen de entrada en un conjunto de rectángulos y, respecto de cada subregión, se va quedando con el máximo valor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu1DIIsrIro2",
        "colab_type": "text"
      },
      "source": [
        "#### Capa clasificadora totalemente conectada (Fully Connected Layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiRbicX_I52p",
        "colab_type": "text"
      },
      "source": [
        "Al final de las capas convolucional y de pooling, las redes utilizan generalmente capas completamente conectadas en la que cada píxel se considera como una neurona separada al igual que en una red neuronal regular. Esta última capa clasificadora tendrá tantas neuronas como el número de clases que se debe predecir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRCD2p1nJSwj",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué es un bottleneck layer?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axoU0jpUJcRV",
        "colab_type": "text"
      },
      "source": [
        "La idea principal detrás de un bottleneck layer (capa de cuello de botella) es reducir el tamaño del tensor de entrada en una capa convolucional con kernels más grandes que 1x1, reduciendo  el número de canales de entrada, también conocida como la profundidad del tensor de entrada.\n",
        "\n",
        "La mayoría de las CNN están utilizando de una forma u otra las capas de cuello de botella. Esta técnica ayuda a mantener bajo el número de parámetros y, por lo tanto, el costo computacional.\n",
        "\n",
        "\n",
        "![](https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/10/Input-Output-layers-313x300.png)\n",
        "\n",
        "Normalmente no se calculan directamente los pesos para las capas de cuello de botella, el proceso de training se encarga de eso, como para todos los demás pesos. Seleccionar un buen tamaño para una capa de cuello de botella es algo que se tiene que “adivinar”, y luego experimentar, para encontrar arquitecturas de red que funcionen bien. El objetivo aquí es generalmente encontrar una red que se generalice bien a las nuevas imágenes, y las capas de cuello de botella ayudan a reducir la cantidad de parámetros en la red al mismo tiempo que permiten que sea profunda y representan muchos mapas de características (feature maps).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaOFdd5JKq0",
        "colab_type": "text"
      },
      "source": [
        "### Arquitectura del modelo MobileNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eTVKzdMKjGy",
        "colab_type": "text"
      },
      "source": [
        "Los cuellos de botella de MobileNetV2 codifican las entradas y salidas intermedias, mientras que la capa interna encapsula la capacidad del modelo para transformarse de conceptos de nivel inferior, como píxeles, a descriptores de nivel superior, como categorías de imágenes. Con las conexiones residuales tradicionales, los accesos directos permiten un entrenamiento más rápido y una mayor precisión. \n",
        "\n",
        "![](https://analyticsindiamag.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-18-at-11.52.51-AM.png)\n",
        "\n",
        "El bloque de construcción básico es una convolución separable en profundidad de cuello de botella con residuos. La arquitectura de MobileNetV2 contiene en su capa inicial completamente una convolución con 32 filtros, seguida de 19 capas de cuello de botella residuales. \n",
        "\n",
        "Los investigadores han adaptado la arquitectura a diferentes puntos de rendimiento, utilizando la resolución de imagen de entrada y el multiplicador de ancho como hiperparámetros ajustables, que pueden ajustarse según la precisión deseada o las compensaciones de rendimiento. La red primaria (multiplicador de ancho 1, 224 × 224), tiene un costo computacional de 300 millones de adiciones múltiples y utiliza 3.4 millones de parámetros. El costo computacional de la red varía de 7 sumas múltiples a 585M MAdds, mientras que el tamaño del modelo varía entre 1.7M y 6.9M parámetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UylzWRRtordO",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué es Transfer Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOP8f-09rgvF",
        "colab_type": "text"
      },
      "source": [
        "![](https://image.slidesharecdn.com/producttank-ai-braincreators-170412101012/95/deep-neural-networks-embeddings-and-transfer-learning-76-638.jpg?cb=1511526967)\n",
        "\n",
        "El aprendizaje por transferencia es una técnica de aprendizaje automático en la que un modelo entrenado en una tarea se vuelve a utilizar en una segunda tarea relacionada.\n",
        "\n",
        "La idea general de la transferencia de aprendizaje es utilizar los conocimientos aprendidos de las tareas para las que se dispone de una gran cantidad de datos etiquetados en configuraciones donde solo hay pocos datos etiquetados. Crear datos etiquetados es costoso, por lo que es clave aprovechar de manera óptima los conjuntos de datos existentes.\n",
        "\n",
        "En un modelo tradicional de aprendizaje automático, el objetivo principal es generalizar datos invisibles basados ​​en patrones aprendidos de los datos de entrenamiento. Con la transferencia de aprendizaje, intenta iniciar este proceso de generalización a partir de patrones que ya se han aprendido para una tarea diferente. Esencialmente, en lugar de comenzar el proceso de aprendizaje desde una hoja en blanco, se comienza a partir de patrones que se han aprendido para resolver una tarea diferente.\n",
        "\n",
        "<image src=http://ruder.io/content/images/2017/03/transfer_learning_setup.png width=700>\n",
        "\n",
        "El aprendizaje por transferencia se relaciona con problemas como el aprendizaje de tareas múltiples y la deriva de conceptos, y no es exclusivamente un área de estudio para el aprendizaje profundo.\n",
        "\n",
        "Sin embargo, el aprendizaje por transferencia es popular en el aprendizaje profundo, dados los enormes recursos necesarios para entrenar modelos de aprendizaje profundo o los conjuntos de datos grandes y desafiantes en los que se capacitan los modelos de aprendizaje profundo.\n",
        "\n",
        "El aprendizaje por transferencia solo funciona en el aprendizaje profundo si las características del modelo aprendidas en la primera tarea son generales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzrCu-W3NDoP",
        "colab_type": "text"
      },
      "source": [
        "Un modelo pre-entrenado  es una red neuronal guardada que se entrenó previamente en un conjunto de datos grande, generalmente en una tarea de clasificación de imágenes a gran escala. Podemos usar el modelo pre-entrenado tal como es o transferir el aprendizaje usando los conventos pre-entrenados. La intuición detrás de transferencia de aprendizaje es que si este modelo se entrena en un conjunto de datos lo suficientemente grande y general, este modelo servirá efectivamente como un modelo genérico del mundo visual. Podemos aprovechar estos mapas de características aprendidas sin tener que entrenar un modelo grande en un conjunto de datos grande utilizando estos modelos como la base de nuestro propio modelo específico para nuestra tarea. *Hay 2 escenarios de aprendizaje por transferencia utilizando un modelo pre-entrenado:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwC03SroM2wa",
        "colab_type": "text"
      },
      "source": [
        "#### Feature Extraction (Extracción de características)\n",
        "\n",
        "Este feature usa las representaciones de lo aprendido por una red neuronal anterior para extraer características significativas de nuevas muestras. Simplemente agregamos un nuevo clasificador, que se entrenará desde cero, sobre el modelo pre-entrenado para que podamos reutilizar los mapas de características aprendidos previamente para nuestro conjunto de datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrZ-cOWeNYlV",
        "colab_type": "text"
      },
      "source": [
        "#### Fine Tuning (Ajuste Preciso)\n",
        "\n",
        "Ésta estrategia no solo consiste en reemplazar y volver a entrenar el clasificador en la parte superior de la CNN en el nuevo conjunto de datos, sino también ajustar los pesos de la red pre-entrenada al continuar la propagación hacia atrás. Es posible ajustar todas las capas de la CNN, o es posible mantener algunas de las capas anteriores fijas (debido a problemas de overfitting) y solo ajustar algunas partes de la red de nivel superior. Esto se debe a la observación de que las características anteriores de una CNN contienen más características genéricas (por ejemplo, detectores de bordes o detectores de manchas de color) que deberían ser útiles para muchas tareas, pero las capas posteriores de la CNN se vuelven progresivamente más específicas para los detalles de las clases contenidas en el dataset original. Por ejemplo, en el caso de ImageNet, que contiene muchas razas de perros, una gran parte de la magnitud de representación de nuestra CNN puede estar dedicado a características que son específicas para diferenciar entre razas de perros, usualmente se maneja en las últimas capas, que son las más especializadas.\n",
        "\n",
        "<image src=https://www.oreilly.com/library/view/java-deep-learning/9781788997454/assets/74b69371-b7bf-47e7-8f0a-9ec9bde897ac.png width=700>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R0SO_b6j4RY",
        "colab_type": "text"
      },
      "source": [
        "### Algoritmos de optimización más utilizados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAhT7K5rkAx_",
        "colab_type": "text"
      },
      "source": [
        "#### Stochastic Gradient Descent (SGD)\n",
        "Es un método de descenso de gradiente optimizado por la tasa de convergencia. La diferencia entre el método de gradiente tradicional es que los elementos se consideran por separado. El descenso de gradiente estocástico (SGD) se aproxima al gradiente utilizando solo un punto de datos. \n",
        "\n",
        "Por lo tanto, la evaluación del gradiente ahorra mucho tiempo en comparación con la suma de todos los datos. Esto es muy útil cuando se trabaja específicamente con grandes conjuntos de datos. Por lo tanto, el gradiente de la función de costo se calculará no para todos los elementos de la muestra, como se hace con el método tradicional de descenso de gradiente, sino para cada elemento por separado. \n",
        "\n",
        "El gradiente calculado para un elemento en particular se toma como una aproximación del gradiente real. \n",
        "Es importante entender que, a diferencia del método tradicional de descenso de gradiente, este algoritmo en cada paso puede no esforzarse por minimizar la función de costo, pero como resultado de un cierto número de pasos, la dirección general tenderá a este mínimo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl2HyAcfkgH2",
        "colab_type": "text"
      },
      "source": [
        "#### Momentum\n",
        "\n",
        "Dado que el método SGD tiene problemas para navegar por los barrancos, es decir, áreas donde la superficie se curva mucho más en una dimensión que en otra, que son comunes alrededor de los óptimos locales. En estos escenarios, el SGD oscila a través de las pendientes del barranco, mientras que solo hace un progreso vacilante en la parte inferior hacia el óptimo local.\n",
        "\n",
        "Momentum es un método que ayuda a acelerar el SGD en la dirección relevante y amortigua las oscilaciones. Esencialmente, cuando usamos el impulso, empujamos una bola cuesta abajo. La bola acumula impulso a medida que rueda cuesta abajo, volviéndose cada vez más rápida en el camino (hasta que alcanza su velocidad máxima). \n",
        "\n",
        "Lo mismo sucede con nuestras actualizaciones de parámetros: el término de momentum (impulso) aumenta para las dimensiones cuyos gradientes apuntan en las mismas direcciones y reduce las actualizaciones para las dimensiones cuyos gradientes cambian de dirección. Como resultado, ganamos una convergencia más rápida y una oscilación reducida.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsXIgqljlFFP",
        "colab_type": "text"
      },
      "source": [
        "#### Adam\n",
        "\n",
        "La estimación del momento adaptativo (Adam)  es un método que calcula las tasas de aprendizaje adaptativo para cada parámetro. Además de almacenar un promedio de decaimiento exponencial de gradientes cuadrados, Adam también mantiene un promedio decreciente exponencial de gradientes pasados de manera similar al Momentum. \n",
        "\n",
        "Mientras que el Momentum puede verse como una bola que corre por una pendiente, Adam se comporta como una bola pesada con fricción, que por lo tanto prefiere mínimos planos en la superficie de error.  \n",
        "\n",
        "Existen muchos otros algoritmos de optimización, cada uno con sus respectivas ventajas así como su desventajas, por lo tanto se enlistan los más comunes.\n",
        "\n",
        "- Nesterov accelerated gradient\n",
        "- Adagrad\n",
        "- Adadelta\n",
        "- RMSprop\n",
        "- AdaMax\n",
        "- Nadam\n",
        "- AMSGrad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1AvXdSzPamr",
        "colab_type": "text"
      },
      "source": [
        "### Preprocesamiento de imágenes para enfocado en una CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-1x9VUfPgLq",
        "colab_type": "text"
      },
      "source": [
        "Hay una serie de pasos de preprocesamiento de imágenes que debemos llevar a cabo antes de usar cualquier dataset de imágenes  en cualquier proyecto de Aprendizaje Profundo.\n",
        "\n",
        "Los parámetros de entrada de datos de imagen más comunes son la cantidad de imágenes, la altura de la imagen, el ancho de la imagen, la cantidad de canales y la cantidad de niveles por píxel. Normalmente, tenemos 3 canales de datos correspondientes a los colores Rojo, Verde, Azul (RGB). Los niveles de píxel son generalmente [0,255]. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFwDFeEUPrGx",
        "colab_type": "text"
      },
      "source": [
        "#### Relación de aspecto uniforme\n",
        "Uuno de los primeros pasos es garantizar que las imágenes tengan el mismo tamaño y relación de aspecto. La mayoría de los modelos de redes neuronales asumen una imagen de entrada de forma cuadrada, lo que significa que cada imagen debe verificarse si es un cuadrado o no, y recortarse de manera apropiada. Se puede recortar para seleccionar una parte cuadrada de la imagen, como se muestra. Mientras recortamos, generalmente nos importa la parte del centro.\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*PIHU_eTWhCUAPBb7-CDf4g.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRCoJXIaP6PI",
        "colab_type": "text"
      },
      "source": [
        "#### Escalado de la imagen\n",
        "Una vez que nos hemos asegurado de que todas las imágenes sean cuadradas (o tengan una relación de aspecto predeterminada), es el momento de escalar cada imagen de manera adecuada. Se tiene  que escalar el ancho y el alto de cada imagen en un factor adecuado para cada imagen. Existe una amplia variedad de técnicas de ampliación y reducción de escala, y usualmente se hace uso una función de biblioteca para hacer esto.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA20G45NQabQ",
        "colab_type": "text"
      },
      "source": [
        "#### Media y Desviación estandar de los datos de entrada (imágenes)\n",
        "\n",
        "A veces es útil observar la \"imagen media\" obtenida al tomar los valores medios de cada píxel en todos los ejemplos de entrenamiento. Observar esto podría darnos una idea de alguna estructura subyacente en las imágenes.\n",
        "\n",
        "Por ejemplo, la imagen media de las primeras 100 de un dataset de prueba se muestra a continuación (*imagen izquierda*).\n",
        "\n",
        "<image src=https://cdn-images-1.medium.com/max/1600/1*iADJswU5cpHZvkEPBbYFzg.png width=400>\n",
        "\n",
        "Claramente, esto tiene la impresión suelta de una cara humana y permite concluir que las caras están algo alineadas con el centro y son de tamaño comparable. \n",
        "\n",
        "La desviación estándar de todas las imágenes se muestra a la derecha. Los valores de mayor varianza se muestran más blancos, por lo que vemos que las imágenes varían mucho en los límites en comparación con el centro.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtL2Cgh0RwV4",
        "colab_type": "text"
      },
      "source": [
        "#### Normalización de las entradas de la imagen\n",
        "\n",
        "La normalización de los datos es un paso importante que garantiza que cada parámetro de entrada (píxel, en este caso) tenga una distribución de datos similar. Esto hace que la convergencia sea más rápida mientras se entrena la red. La normalización de los datos se realiza restando la media de cada píxel y luego dividiendo el resultado por la desviación estándar. La distribución de dichos datos se asemejaría a una curva gaussiana centrada en cero. Para las entradas de imágenes necesitamos que los números de píxeles sean positivos, por lo que se puede  elegir escalar los datos normalizados en el rango [0,1] o [0, 255]. \n",
        "\n",
        "> *Ejemplo de un dataset de 100 imágenes despues de aplicar la normalizacion a cada una de las imágenes:*\n",
        "<image src=https://cdn-images-1.medium.com/max/1600/1*FnEVS0Gpj6rtaY-Z3kpXeQ.png width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X17UGLv7SXED",
        "colab_type": "text"
      },
      "source": [
        "#### Reducción de la dimensionalidad\n",
        "\n",
        "En ocasiones se puede optar por colapsar los canales RGB en un solo canal de escala de grises. A menudo hay consideraciones para reducir otras dimensiones, cuando se permite que el rendimiento de la red neuronal sea invariante a esa dimensión, o para hacer que el problema de entrenamiento sea más manejable.\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*zskFgRsuv7Iq2Jb7-jTxfA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12oZ3tAUrgoi",
        "colab_type": "text"
      },
      "source": [
        "## Implementando Transfer Learning en base a una CNN entrenada con ImageNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWunnp-aNdSL",
        "colab_type": "text"
      },
      "source": [
        "### Importando nuestro propio repositorio de imágenes desde Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vUBiovqFTZU",
        "colab_type": "code",
        "outputId": "8c1c08e0-f4e0-4eaf-c264-8570ec6f1478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "! git clone https://github.com/Omaralon/Naruto-character-classification.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Naruto-character-classification'...\n",
            "remote: Enumerating objects: 556, done.\u001b[K\n",
            "remote: Counting objects: 100% (556/556), done.\u001b[K\n",
            "remote: Compressing objects: 100% (546/546), done.\u001b[K\n",
            "remote: Total 556 (delta 10), reused 555 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (556/556), 17.79 MiB | 28.87 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7e1lZ_ANozk",
        "colab_type": "text"
      },
      "source": [
        "### Importando bibliotecas importantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBfkFDZ9Fuug",
        "colab_type": "code",
        "outputId": "5fb78b55-8c6a-4e82-db4f-5b6fe5be5630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tf-nightly-gpu-2.0-preview\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu-2.0-preview in /usr/local/lib/python3.6/dist-packages (2.0.0.dev20190602)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.33.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.11.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.1.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.16.4)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.14.0.dev2019060200)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.14.0a20190602)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-gpu-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-gpu-2.0-preview) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview) (0.15.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSQ-IVXiF35y",
        "colab_type": "code",
        "outputId": "c3fcf942-5aaf-456d-b198-f67300dff607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-dev20190602'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIvS7TmeTBTW",
        "colab_type": "text"
      },
      "source": [
        "### Verificando el contenido de nuestro dataset (labels y muestras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1hy_OvIGHl_",
        "colab_type": "code",
        "outputId": "350dd889-6efb-4014-bb3d-54f0f347f3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ls Naruto-character-classification/Naruto_images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mGaara\u001b[0m/    \u001b[01;34mKakashi\u001b[0m/   \u001b[01;34mOrochimaru\u001b[0m/  \u001b[01;34m'Rock lee'\u001b[0m/   \u001b[01;34mSasuke\u001b[0m/\n",
            " \u001b[01;34mJiraya\u001b[0m/   \u001b[01;34mNaruto\u001b[0m/    \u001b[01;34mPain\u001b[0m/         \u001b[01;34mSakura\u001b[0m/      \u001b[01;34mTsunade\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flBy28c9GKZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = './Naruto-character-classification/Naruto_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVjZo0M8N55J",
        "colab_type": "text"
      },
      "source": [
        "### Preprocesando nuestras imágenes\n",
        "Nuestras imágenes que le alimentemos al modelo, como entradas, deben ser de 224x224 píxeles, es por eso que utilizamos nuestro **ImageDataGenerator** para reescalar las imágenes a ese tamaño y, además normalizamos los valores de cada pixel. De esta manera en el parámetro **rescale** especificamos que los valores serán en un rango de 0 a 1, en vez de pertenecer a un rango de 0 a 255. Ésto se hace para que nuestro modelo no maneje valores tan grandes y, por ende, no utilice tanto procesamiento. Lo que nos lleva a una convergencia más rápida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABtJ-a4RO8HK",
        "colab_type": "text"
      },
      "source": [
        "Creamos un generator para el set de entrenamiento y otro para el set de evaluación, al cual le corresponde solamente el 20% de las imágenes de nuestro dataset. Al crear éstos objetos, especificamos el directorio en el que se encuentra nuestro dataset, el tamaño de la imagen y  tamaño del lote de imágenes que tendremos en cada iteración **(epoch)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yR9FwCMGS03",
        "colab_type": "code",
        "outputId": "31069f02-9130-4a01-91e5-b648dbbf24b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 6\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 239 images belonging to 10 classes.\n",
            "Found 57 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoLR4vxEG_Qe",
        "colab_type": "text"
      },
      "source": [
        "En este caso tenemos un batch de 6 imágenes por iteración, el tamaño de cada imagen es ajustado a 224 x 224 porque nuestro modelo preentrenado MobileNet V2 ocupa como entradas, matrices de 224x224. Y como manejamos 3 canales RGB, aumenta el shape de nuestra matriz de input. A diferencia de si manejáramos imágenes en escala de grises, las cuales sólo ocupan un canal, como lo es en el caso del dataset MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMjRxSs8GhnJ",
        "colab_type": "code",
        "outputId": "e136cd66-c2bc-4aa9-8bd3-ccf536bd262f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6, 224, 224, 3), (6, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpUSsOfZBal",
        "colab_type": "text"
      },
      "source": [
        "### Guardando labels de nuestro modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKF--g1kGqWF",
        "colab_type": "text"
      },
      "source": [
        "- Por el momento solamente guardaremos los labels en un archivo **labels.txt** los cuales ocuparemos más adelante al convertir nuestro modelo a un formato de Tensorflow Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb2JCWkDGoEQ",
        "colab_type": "code",
        "outputId": "5b92a142-3211-4e9d-a6bc-7d059376091b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Gaara': 0, 'Jiraya': 1, 'Kakashi': 2, 'Naruto': 3, 'Orochimaru': 4, 'Pain': 5, 'Rock lee': 6, 'Sakura': 7, 'Sasuke': 8, 'Tsunade': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QZiObBwQwEO",
        "colab_type": "text"
      },
      "source": [
        "- Comprobamos que nuestro archivo de texto haya sido escrito correctamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP6pybW3G1wH",
        "colab_type": "code",
        "outputId": "6918c005-e9a9-4caf-a4c3-a5c914a4e994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "!cat labels.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gaara\n",
            "Jiraya\n",
            "Kakashi\n",
            "Naruto\n",
            "Orochimaru\n",
            "Pain\n",
            "Rock lee\n",
            "Sakura\n",
            "Sasuke\n",
            "Tsunade"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8EixY6IHw6f",
        "colab_type": "text"
      },
      "source": [
        "- En este caso utilizamos una red neuronal previamente entrenada. En donde especificamos que no queremos incluir la última capa (top) porque la útlima capa es la de salida, y nosotros queremos tener otras labels como salida de nuestro modelo al aplicar aprendizaje por transferencia.\n",
        "\n",
        "- El motivo de que no incluyamos la capa del top es porque las últimas capas de una red neuronal son las que tienen características más especializadas acorde al problema para el cual se entrenó. Por lo que solo conservamos las capas anteriores porque éstas tienen características genéricas, como lo es el reconocimiento de bordes, manchas, líneas y patrones en general, que nos servirán para resolver problemas de clasificación de imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnCEXZM3G4mN",
        "colab_type": "code",
        "outputId": "e6472b1e-a725-4355-a2da-15237d53bff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "somxi5t3SMvl",
        "colab_type": "text"
      },
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwEIEcN2SQg5",
        "colab_type": "text"
      },
      "source": [
        "You will freeze the convolutional base created from the previous step and use that as a feature extractor, add a classifier on top of it and train the top-level classifier.\n",
        "\n",
        "Para efecutar un correcto feature extraction deberemos congelar nuestro modelo base convolucional (MobileNetV y los usaremos como un extractor de características, agregaremos un clasificador encima (una nueva capas con neuronas) y sólo entrenaremos a éste nuevo clasificador que habremos agregado en el nivel superior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSyUG_eWSayX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD6MzZUUSrQI",
        "colab_type": "text"
      },
      "source": [
        "### Agregamos una última capa (head) clasificadora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWOlu9CaRe-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agregaremos en la ultima capa una Dense Layer con un numero de nodos igual a 10, que son nuestras labels\n",
        "num_classes = 10\n",
        "\n",
        "new_model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),   # Creamos una Capa Convolutiva 2D con 32 filtros con un tamaño de 3x3 y con una funcion de activacion relu\n",
        "  tf.keras.layers.Dropout(0.2),   # Esta capa nos ayuda a prevenir overfitting. El dropout de que se aplicara es del 20%\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),   # Aplicamos una capa de Average Pooling\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax')  # La funcion de activacion de esta capa densa de salida es softmax\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvpPnCCnfoW",
        "colab_type": "text"
      },
      "source": [
        "En nuestro caso nos basta con realizar el Feature Extraction en base al modelo MobileNetV2, esto es porque no contamos con suficientes imágenes como para poder realizar Fine tuning con lo que podríamos encontrar mejores pesos al ir actualizando diferentes capas de nuestro modelo base. \n",
        "\n",
        "> - Si hiciéramos Fine tuning con nuestro dataset, el cual es muy pequeño, lo más probable es que llegaríamos a un estado de Overfitting por no tener muchos datos de los cuales confiar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVDSH80-S8Ad",
        "colab_type": "text"
      },
      "source": [
        "### Compilamos el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFifToIRS_I1",
        "colab_type": "text"
      },
      "source": [
        "- Debemos de compilar el modelo antes de poder entrenarlo, en la compilación indicamos las métricas que utilizaremos en nuestro modelo.\n",
        "\n",
        "- Elegimos como método de optimización un gradiente descendente estocástico **(SGD)**, una función de error o loss function como **crossentropy** para clasificación y nuestra métrica de validación fue de** precisión**.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R0V3EEMINcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.compile(optimizer='sgd', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnQVpUeTIOyg",
        "colab_type": "code",
        "outputId": "01ab78de-d249-4e3a-f4f6-7a7c3812b31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 5, 5, 32)          368672    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 2,626,986\n",
            "Trainable params: 369,002\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqLtEXFjYRvh",
        "colab_type": "text"
      },
      "source": [
        "- Observamos que tenemos 2,626,986 parámetros en nuestro modelo completo, sin embargo sólo 369,002 son entrenables (los podemos actualizar) debido a que congelamos los pesos del modelo MobileNetV2 del cual nos estamos basando como fuente de conocimiento para el aprendizaje por transferencia. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW2wGpJlZrGu",
        "colab_type": "text"
      },
      "source": [
        "### Entrenamos nuestro nuevo clasificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "100FmXsFIVtV",
        "colab_type": "code",
        "outputId": "07d638d6-ad8a-4b9a-b85a-08642762e9e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "epochs = 5    # Elegimos 5 iteraciones porque contamos con 30 imagenes por personaje y nuestro batch size fue de 6\n",
        "\n",
        "fit_stats = new_model.fit(train_generator, \n",
        "                    epochs=epochs, \n",
        "                    validation_data=val_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0603 03:13:43.224878 139710054885248 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "40/40 [==============================] - 39s 983ms/step - loss: 2.3702 - accuracy: 0.1883 - val_loss: 2.1244 - val_accuracy: 0.3333\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 30s 747ms/step - loss: 1.8804 - accuracy: 0.3264 - val_loss: 1.7490 - val_accuracy: 0.3684\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 30s 756ms/step - loss: 1.3069 - accuracy: 0.5690 - val_loss: 1.9445 - val_accuracy: 0.4035\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 30s 749ms/step - loss: 0.8664 - accuracy: 0.7448 - val_loss: 3.6971 - val_accuracy: 0.2105\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 30s 761ms/step - loss: 0.4497 - accuracy: 0.8368 - val_loss: 2.0290 - val_accuracy: 0.4211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VrTfy1rZ09X",
        "colab_type": "text"
      },
      "source": [
        "### Gráficos del desempeño de la precisión y el error resultante\n",
        "\n",
        "Gracias al códigod e arriba pudimos apreciar que al término de la 5ta iteración obtenemos una precisión del 83%, la cual es muy buena tomando en consideración el tamaño de nuestro dataset (muy pequeño), además de que todas las imágenes no son tan consitentes (no todas las imágenes de los personajes se muestran del mismo ángulo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IQEurdLOs9q",
        "colab_type": "code",
        "outputId": "71f763ee-b365-4644-9e67-c336e68742ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "acc = fit_stats.history['accuracy']\n",
        "val_acc = fit_stats.history['val_accuracy']\n",
        "\n",
        "loss = fit_stats.history['loss']\n",
        "val_loss = fit_stats.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,4.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHwCAYAAAC/hfaiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am0Z2Dgzatle",
        "colab_type": "text"
      },
      "source": [
        "- Podemos apreciar que los valores de entrenamiento siempre siguen un comportamiento lineal.\n",
        "- A medida que vamos avanzando en el número de iteración, la precisión de entrenamiento va incrementando y el error del entrenamiento va disminuyendo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7vcaHFmpAkg",
        "colab_type": "text"
      },
      "source": [
        "### Guardando nuestro modelo y convirtiéndolo a formato de TFLITE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYbSogtrQtBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model_dir = 'save/'\n",
        "tf.saved_model.save(new_model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wtkoyvcQxQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model_naruto_classif.tflite')\n",
        "files.download('labels_naruto_classif.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaJ-axPkmWLm",
        "colab_type": "text"
      },
      "source": [
        "## Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9nv-ekFmYSS",
        "colab_type": "text"
      },
      "source": [
        "- https://stackoverflow.com/questions/54702212/keras-rescale-1-255-vs-preprocessing-function-preprocess-input-which-one-to\n",
        "- https://stackoverflow.com/questions/55136609/keras-imagedatagenerator-rescale-values-to-0-5-0-5\n",
        "- https://stackoverflow.com/questions/41758385/resizing-images-in-keras-imagedatagenerator-flow-methods\n",
        "- https://stats.stackexchange.com/questions/262044/what-does-a-bottleneck-layer-mean-in-neural-networks\n",
        "- https://towardsdatascience.com/speeding-up-convolutional-neural-networks-240beac5e30f\n",
        "- https://towardsdatascience.com/neural-network-architectures-156e5bad51ba\n",
        "- https://ai.stackexchange.com/questions/4864/what-is-the-concept-of-tensorflow-bottlenecks\n",
        "- http://cs231n.github.io/transfer-learning/\n",
        "- https://medium.com/@mehulved1503/feature-selection-and-feature-extraction-in-machine-learning-an-overview-57891c595e96\n",
        "- https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/\n",
        "- https://machinelearningmastery.com/transfer-learning-for-deep-learning/\n",
        "- https://www.datacamp.com/community/tutorials/transfer-learning\n",
        "- https://machinethink.net/blog/mobilenet-v2/\n",
        "\n",
        "\n"
      ]
    }
  ]
}